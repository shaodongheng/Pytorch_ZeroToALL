## 2.1 基础知识

### 2.1.1 张量（Tensor）

Tensor是pytorch中最基本的操作对象。

1. tensor的不同数据类型：

| 数据类型           | 数据类型   |
| ------------------ | ---------- |
| torch.FloatTensor  | 32位浮点型 |
| torch.DoubleTensor | 64位浮点型 |
| torch.ShortTensor  | 16位整型   |
| torch.IntTensor    | 32位整型   |
| torch.LongTensor   | 64位整型   |

2. tensor的定义

   ```python
   a = torch.Tensor([[2,3],[4,8],[7,9]]) #直接定义一个3x2的tensor
   print(a,a.size()) #查看tensor的大小
   ```

   输出：

   ![image-20200417140804459](https://github.com/shaodongheng/cloudimage/blob/master/img/image-20200417140804459.png?raw=true)

注意：*torch.Tensor* 默认是32位浮点型。

当然还可以：

```python
b = torch.LongTensor([[2,3],[4,5],[6,7]])
```

0初始化和正态分布随机初始化：

```python
c = torch.zeros((3,2))  #初始化一个3x2的值为0的tensor
d = torch.randn((3,2))
```

3. 索引

   与numpy数组的方式相同

   ```python
   a[0,1] = 100   #修改张量a的[0,1]处的值为100
   ```

4. Tensor 和numpy.ndarray 之间的转换



+ tensor转换成numpy数组

```python
b = torch.LongTensor([[2,3],[4,5],[6,7]])
numpy_b = b.numpy() # tensor to ndarray
```

   b:

![image-20200417155933765](https://github.com/shaodongheng/cloudimage/blob/master/img/image-20200417155933765.png?raw=true)

   numpy_b:

![image-20200417160012703](https://github.com/shaodongheng/cloudimage/blob/master/img/image-20200417160012703.png?raw=true)

+ numpy数组转换成tensor

```python
import numpy as np
e = np.array([[1,2],[3,4]])  #定义一个numpy数组
torch_e = torch.from_numpy(e)  #ndarray to tensor
```

   e:

![image-20200417160534857](https://github.com/shaodongheng/cloudimage/blob/master/img/image-20200417160534857.png?raw=true)

  torch_e:

![image-20200417160555075](https://github.com/shaodongheng/cloudimage/blob/master/img/image-20200417160555075.png?raw=true)

+ 修改tensor的数据类型

```
f_torch_e = torch_e.float()
```

torch_e.type():

```
'torch.IntTensor'
```

f_torch_e.type():

```0
'torch.FloatTensor'
```

5. 将Tensor放入GPU

   numpy数组只能在cpu上运行，tensor可以放入GPU运行

   ```python
   if torch.cuda.is_available():  #判断运行环境是否支持GPU
       a_cuda = a.cuda()  #将张量a放入GPU
       print(a_cuda)
   ```

   输出：

   ![image-20200417161446063](https://raw.githubusercontent.com/shaodongheng/cloudimage/master/img/image-20200417161446063.png)

### 2.1.2 变量（Variable）

变量提供了自动求导功能。

通过torch.autograd.Variable导入Variable。

1. 将一个tensor变成Variable

将tensor放入Variable即可：

```python
Variable(a)
```

2. Variable的三个部分（求梯度）

Variable由三个部分组成：data，grad，grad_fn。

通过data可以获取Variable的tensor数值。

grad_fn 表示得到这个Variable的操作，例如加减乘除。

grad 是这个Variable的梯度。

```python
from torch.autograd import Variable #导入Variable

x = Variable(torch.Tensor([1]), requires_grad = True)
#requires_grad = True 表示需要求这个变量的梯度
w = Variable(torch.Tensor([2]), requires_grad = True)
b = Variable(torch.Tensor([3]), requires_grad = True)

y = w * x + b

y.backward() #反向自动求导
           
print(x.grad)  #获取查看Variable的梯度
print(w.grad)
print(b.grad)
```

```输出
输出：
tensor([2.])
tensor([1.])
tensor([1.])
```

如果我们想要求一个Variable的梯度，需要设置requires_grad= True。

pytorch可以通过y.backward()来实现自动求导，在上述代码，完整的语句应该是：

```python
y.backward(torch.FloatTensor([1]))  #表示在变量为1处的梯度
```

在对于标量求导时可以里面的参数不写。

3. 向量矩阵自动求导

```python
x= torch.randn(3)
x=Variable(x,requires_grad = True)
print(x)
y = x*2

print(y)

y.backward(torch.FloatTensor([1, 0.1, 0.01]))
#表示求[1，0.1，0.01]处的梯度，在这里就是原本的梯度分别乘以1，0.1，0.01
print(x.grad)
```

```output
输出:
tensor([-0.7970, -1.7851,  0.3690], requires_grad=True)
tensor([-1.5941, -3.5702,  0.7381], grad_fn=<MulBackward0>)
tensor([2.0000, 0.2000, 0.0200]) #每个分量的梯度
```

注意：这里就不能写y.backward()，而是要把参数完整。

### 2.1.3 数据集

### 2.1.4 模组（nn.module)

### 2.1.5 优化（torch.optim)

### 2.1.6 模型的保存和加载

主要存在两种方式：

1. 保存整个模型的结构信息和参数信息：

   ```python
   torch.save(model,'./model.pth')
   ```

   对应的加载模式：

   ```python
   load_model = torch.load('model.pth')
   ```

2. 只保存模型的参数：

   ```python
   torch.save(model.state_dict(), './model_state.pth')
   ```

   对应的加载模式：

   首先需要导入模型的结构，

   ```python
   model.load_state_dic(torch.load('model_state.pth'))
   ```

   